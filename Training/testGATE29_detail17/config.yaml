# '''
# detail:
# This is followed by training the detail model (i.e. ğ¸ğ‘‘
# and ğ¹ğ‘‘
# ) on VGGFace2 and VoxCeleb2 with a batch size of 6, with
# 3 images per subject, and parameters ğœ†ğ‘â„ğ‘œğ· = 2.0, ğœ†ğ‘šğ‘Ÿ ğ‘“ = 5ğ‘’ âˆ’ 2,
# ğœ†ğ‘ ğ‘¦ğ‘š = 5ğ‘’ âˆ’ 3, ğœ†ğ‘‘ğ‘ = 1.0, and ğœ†ğ‘Ÿğ‘’ğ‘”ğ· = 5ğ‘’ âˆ’ 3.

# why:
# '''
# pretrained_modelpath: '/ps/scratch/yfeng/Data/Projects-data/DECA-training/training/DECA_SIGGRAPH/pretrain/model.tar'
output_dir: "Training/testGATE29_detail17" # No photometric loss only au loss
pretrained_modelpath: "Training/testGATE29/model.tar"
dataset:
  batch_size: 16
  K: 1
loss:
  photo_D: 2.5
  reg_sym: 0.005
  reg_z: 0.005
  reg_diff: 0.005
  au_D: 15.
  mrf: 0.05
train:
  train_detail: True
  vis_au: True
  resume: True
  max_epochs: 10
  max_steps: 1000000
  log_steps: 200
  vis_steps: 100
  stepLR_steps: 10000
  checkpoint_steps: 1000
  lr: 0.0001
  # val_steps: 500
  # eval_steps: 1000
# dataset:
#   training_data: ['vggface2', 'vox2']
# python main_train_deca_release.py --cfg configs/release_version/deca_coarse.yml