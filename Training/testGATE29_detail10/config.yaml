# '''
# detail:
# This is followed by training the detail model (i.e. ð¸ð‘‘
# and ð¹ð‘‘
# ) on VGGFace2 and VoxCeleb2 with a batch size of 6, with
# 3 images per subject, and parameters ðœ†ð‘â„Žð‘œð· = 2.0, ðœ†ð‘šð‘Ÿ ð‘“ = 5ð‘’ âˆ’ 2,
# ðœ†ð‘ ð‘¦ð‘š = 5ð‘’ âˆ’ 3, ðœ†ð‘‘ð‘ = 1.0, and ðœ†ð‘Ÿð‘’ð‘”ð· = 5ð‘’ âˆ’ 3.

# why:
# '''
# pretrained_modelpath: '/ps/scratch/yfeng/Data/Projects-data/DECA-training/training/DECA_SIGGRAPH/pretrain/model.tar'
output_dir: "Training/testGATE29_detail10" # GATE_detail!, Enable train for E_detail, mse on class up, eye mouth 0.5 (mask), lr 0.000005->0.0001
pretrained_modelpath: "Training/testGATE29/model.tar"
dataset:
  batch_size: 8
  K: 1
loss:
  photo_D: 1.0
  reg_sym: 0.005
  reg_z: 0.5
  reg_diff: 0.005
  au_D: 2.0
  mrf: 0.05
train:
  train_detail: True
  vis_au: True
  resume: True
  max_epochs: 10
  max_steps: 1000000
  log_steps: 200
  vis_steps: 100
  stepLR_steps: 10000
  checkpoint_steps: 1000
  lr: 0.0001
  # val_steps: 500
  # eval_steps: 1000
# dataset:
#   training_data: ['vggface2', 'vox2']
# python main_train_deca_release.py --cfg configs/release_version/deca_coarse.yml